Выполнил Федотов Р. А., 531 гр.
 

1. Основные исходные предположения causal discovery?
 
На протяжении всей работы авторы делают следующие стандартные предположения для casual discovery:
 
Предположение 1 (Casual Sufficiency). Не существует скрытых факторов, и все случайные переменные
представляющие интерес, являются наблюдаемыми.
 
Предположение 2 (о конечности выборки). Имеется конечное число выборок для наблюдения/вмешательства.
 
Предположение 3 (нелинейность структурной причинно-следственная модели с аддитивным шумом). Структурная причинно-следственная модель имеет нелинейные условные ожидания с аддитивным гауссовским шумом.
 
Предположение 4 (единственная цель). Каждое вмешательство является атомарным и применяется к единственному таргету структурной причинно-следственной модели.

2. Как связаны BCN и SCM?
 
Модель Causal Bayesian Network: это пара (g, P), такая что для любого подмножества вершин DAG-а W выполняется условие зависимости условных распределений X_V относительно интервенций do(X_W = x’_W) от родительских вершин pa_g(i), i = V\W, не входящих в множество W.
 
Модель Structural Causal Model: это генеративная модель на DAG-е g, т. е. здесь мы считаем, что вся ошибка сосредоточена лишь в случайной величине eps_i и значения X_i в вершинах DAG-а зависят от своих родительских вершин нелинейно, т. е. X_i = f_i(X_pa_g_i, eps_i). Считаем, что e_i это экзогенные попарно независимые случайные величины, шум. Записав такую функциональную зависимость для каждой вершины графа, получаем SCM модель. Важный частный случай: Gaussian additive noise модель, где f(X, eps) = X + eps, eps распределена нормально со средним 0 и одинаковой дисперсией sigma^2.
 
3.Каким образом MI используется в дизайне эксперимента?
 
Авторы решили, что цель произвольного эксперимента с таким DAG-ом - получение максимальной информации о распределениях в вершинах (в байесовском случае) либо получение информации о функциональных зависимостях в SCM случае. Для этого путем интервенций изменяется состояние системы графа.
 
В общем случае ставится следующий критерий оптимизации: подобрать дизайн эксперимента (интервенцию) в граф так, чтобы максимизировать information gain Ф после эксперимента. В частном случае SCM цель интервенции - максимизировать mutual information для данной вершины X. 
 
4.Объясните простыми словами что такое SCM
 
Предположим, что у нас есть какой-то сложный, нелинейный процесс. Мы пытаемся формализовать его с помощью последовательности событий, заключенных в DAG (естественная модель последовательных событий), где вершина есть некоторый этап или ступень процесса. Наша цель - изучить влияние процессов из прошлого (родительских вершин) на процессы в настоящем (последние вершины без потомков). Единственный способ изучить такое влияние - взаимодействовать с таким графом, т. е. менять состояние модели (формализованное случайной величиной в вершине). Далее мы считаем, что между случайными величинами в вершинах есть некоторая функциональная зависимость.
 
5.Как можно интерпретировать веса в вершинах графа
 
В случае линейной SCM (т. е. в случае функциональной зависимости между родительскими и дочерними вершинами в виде линейных функций) веса в вершинах можно интерпретировать как «мера влияния» случайного процесса-предшественника на свой процесс-потомок (вес распределения предка в смеси распределения потомка в байесовском случае)
 
6.Преимущества алгоритма по сравнению с related-работами
 
Можно использовать нелинейные зависимости; интервенции не обязаны быть последовательными, а могут быть одновременными в разные вершины; в других работах использовали дерево вместо DAG-а (неудобное ограничение); можно запускать алгоритм по батчам из выборки;